{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, lxml\n",
    "from lxml import etree\n",
    "import time\n",
    "import random\n",
    "import io\n",
    "import logging\n",
    "import os\n",
    "from abc import ABC, abstractmethod\n",
    "import argparse\n",
    "\n",
    "\n",
    "def get_logger(name, log_filename=None):\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter(fmt=\"%(name)s - %(levelname)s\\t%(message)s\", datefmt=\"%Y/%m/%d %H:%M:%S\")\n",
    "    \n",
    "    shandler = logging.StreamHandler(sys.stdout)\n",
    "    shandler.setFormatter(formatter)\n",
    "    logger.addHandler(shandler)\n",
    "    \n",
    "    if log_filename is not None:\n",
    "        fhandler = logging.FileHandler(log_filename, mode='a', encoding='utf8')\n",
    "        fhandler.setFormatter(formatter)\n",
    "        logger.addHandler(fhandler)\n",
    "        \n",
    "    return logger\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--debug\", type=bool, default=False)\n",
    "    parser.add_argument(\"--verbose\", type=bool, default=True)\n",
    "    args = parser.parse_args([])\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, lxml\n",
    "from lxml import etree\n",
    "import time\n",
    "import random\n",
    "import io\n",
    "import logging\n",
    "import os, sys\n",
    "from abc import ABC, abstractmethod\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from utils import get_logger, get_args\n",
    "\n",
    "logger = get_logger(__name__, 'crawler.log')\n",
    "\n",
    "class Sleep:\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "        self.visit_cnt = 0\n",
    "    \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        if self.visit_cnt > 4:\n",
    "            time.sleep(2 + random.random() * 4)\n",
    "        else:\n",
    "            self.visit_cnt += 1\n",
    "        self.func(*args, **kwargs)\n",
    "\n",
    "class Crawler(ABC):\n",
    "    def __init__(self, args):\n",
    "        self.name = None\n",
    "        self.main_url = None\n",
    "        self.main_page = None\n",
    "        self.src_store_url = None\n",
    "        self.src_ext = ['doc', 'docx', 'pdf', 'txt', 'xlsx', 'xls', 'ppt', 'zip', 'tar', '7z', 'rar',\n",
    "                        'png', 'jpg', 'gif', 'jpeg']\n",
    "        \n",
    "        self.args = args\n",
    "        self.page_url = None\n",
    "        # self.store_2_page_list_xpath = None\n",
    "        # self.download_page_2_file_xpath = None\n",
    "        \n",
    "        self.visit_cnt = 0      # to control QPS, not used currently\n",
    "        self.desc = \"Crawler for {name}\\n\" \\\n",
    "                    \"Home page: {main_page}\"\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.desc.format(name=self.name, main_page=self.main_page)\n",
    "    \n",
    "    def sleep(self):\n",
    "        time.sleep(0.5 + random.random() * 1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_etree_html(url):\n",
    "        time.sleep(0.5 + random.random() * 1)\n",
    "        response = requests.get(url)\n",
    "        html = response.content\n",
    "        return etree.HTML(html)\n",
    "    \n",
    "    def download_src(self, url, ext, name, save_path='./'):\n",
    "        self.sleep()\n",
    "        if not os.path.exists(save_path):\n",
    "            os.mkdir(save_path)\n",
    "        if ext not in self.src_ext:\n",
    "            logger.info(f\"Illegal ext to download: {url}\")\n",
    "            return\n",
    "        # self.visit_cnt = Crawler.sleep(self.visit_cnt)\n",
    "        \n",
    "        src = requests.get(url)\n",
    "        content = io.BytesIO(src.content)\n",
    "        if name.split('.')[-1] not in self.src_ext:\n",
    "            name = name + '.' + ext\n",
    "        if name in os.listdir(save_path):\n",
    "            logger.info(f'>>> {name} exists! Pass <<<')\n",
    "            return\n",
    "    \n",
    "        fname = os.path.join(save_path, name)\n",
    "        with open(fname, 'wb') as f:\n",
    "            f.write(content.read())\n",
    "        logger.info(f'>>> {fname} has been downloaded <<<')\n",
    "        \n",
    "    def process_urls(self, urls, host_url):\n",
    "        if isinstance(urls, list or tuple):\n",
    "            assert host_url is not None or all([not url.startswith('/') for url in urls]), \\\n",
    "                f\"{urls} contains some urls without prefix while host_url is None!\"\n",
    "        else:\n",
    "            assert host_url is not None or not urls.startswith('/'), \\\n",
    "                f\"{urls} has no prefix while host_url is None!\"\n",
    "        if host_url is not None:\n",
    "            if isinstance(urls, str):\n",
    "                urls = host_url + urls if urls.startswith('/') else urls\n",
    "            else:\n",
    "                urls = [host_url + url if url.startswith('/') else url for url in urls]\n",
    "        return urls\n",
    "        \n",
    "    def get_src_from_store(self, src_urls, src_names, host_url=None, save_path='./'):\n",
    "\n",
    "        for cnt, (url, name) in enumerate(zip(src_urls, src_names)):\n",
    "            ext = url.split('.')[-1]\n",
    "            if self.args.verbose:\n",
    "                logger.info(f\"Downloading from src page {cnt} - Current EXT: {ext}\")\n",
    "            if ext not in self.src_ext:     # url directs to a page but not src file\n",
    "                cur_src_urls, cur_src_names = self.get_src_from_page(url, host_url=host_url)\n",
    "                if self.args.verbose:\n",
    "                    logger.info(f\"Files of current page: {list(zip(cur_src_names, cur_src_urls))}\")\n",
    "                for url_, name_ in zip(cur_src_urls, cur_src_names):\n",
    "                    ext_ = url_.split('.')[-1]\n",
    "                    # print(url_)\n",
    "                    self.download_src(url_, ext_, name_, save_path)\n",
    "            else:\n",
    "                self.download_src(url, ext, name, save_path)\n",
    "            \n",
    "            if self.args.debug and cnt >= 1:\n",
    "                break\n",
    "    \n",
    "    def get_src_urls(self, url, host_url=None):\n",
    "        # get src pages from the download center(s)\n",
    "        if isinstance(url, list or tuple):\n",
    "            src_urls, src_names = [], []\n",
    "            for url_, page_url_ in zip(url, self.page_url):\n",
    "                logger.info(f\"getting the src_urls list of center {url_}...\")\n",
    "                src_urls_, src_names_ = [], []\n",
    "                src_urls_, src_names_ = self._get_src_urls(url_, page_url_)\n",
    "                src_urls += src_urls_\n",
    "                src_names += src_names_\n",
    "        else:\n",
    "            src_urls, src_names = self._get_src_urls(url, self.page_url)\n",
    "        src_urls = self.process_urls(src_urls, host_url)\n",
    "        return src_urls, src_names\n",
    "    \n",
    "    @abstractmethod \n",
    "    def _get_src_urls(self, url, page_url=None):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    @abstractmethod \n",
    "    def _get_src_from_page(self, element):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def get_src_from_page(self, url, host_url=None):\n",
    "        url = self.process_urls(url, host_url)\n",
    "        element = Crawler.get_etree_html(url)\n",
    "        src_urls, src_names = self._get_src_from_page(element)\n",
    "        src_urls = self.process_urls(src_urls, host_url)\n",
    "        return src_urls, src_names\n",
    "    # @abstractmethod \n",
    "    # def get_nav_item(self, url):\n",
    "    #     raise NotImplementedError()\n",
    "\n",
    "    def crawl_src(self, host_url=None, save_path='./'):\n",
    "        if self.src_store_url is None:\n",
    "            logger.info(f\"{self.name}没有资源下载网页！\")\n",
    "            return\n",
    "        logger.info(f\"Downloading src files for {self.name}...\")\n",
    "        \n",
    "        src_urls, src_names = self.get_src_urls(self.src_store_url, host_url)\n",
    "        logger.info(f\"All src pages: \\n{list(zip(src_names, src_urls))}\")\n",
    "        self.get_src_from_store(src_urls, src_names, host_url, save_path)\n",
    "        \n",
    "        logger.info(f\"Done\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SISTCrawler(Crawler):\n",
    "    def __init__(self, args):\n",
    "        super().__init__(args)\n",
    "        self.name = '信息科学技术学院'\n",
    "        self.main_url = 'https://sist.ustc.edu.cn/'\n",
    "        self.main_page = 'https://sist.ustc.edu.cn/main.htm'\n",
    "        self.src_store_url = [\n",
    "            # 'https://sist.ustc.edu.cn/5104/list.htm',       # 研究生\n",
    "            'https://sist.ustc.edu.cn/5111/list.htm',       # 本科生\n",
    "            # 'https://sist.ustc.edu.cn/5128/list.htm',       # 党建\n",
    "            'https://sist.ustc.edu.cn/5095/list.htm',       # 学生工作\n",
    "            # 'https://sist.ustc.edu.cn/5085/list.htm',       # 科学研究\n",
    "            'https://sist.ustc.edu.cn/5079/list.htm',       # 信息服务\n",
    "        ]\n",
    "        self.page_url = [url[:-4] + '{id}' + url[-4:] for url in self.src_store_url[:4]] + \\\n",
    "                        [None, None]\n",
    "        self.page_url = ['https://sist.ustc.edu.cn/5111/list{id}.htm', 'https://sist.ustc.edu.cn/5095/list{id}.htm',\n",
    "                          None]\n",
    "        # self.max_page_num_xpath = None\n",
    "        \n",
    "        # self.store_2_page_list_xpath = \"//div[@class='view_bg']//a\"\n",
    "        # self.name_holder = \"\"\n",
    "        \n",
    "    def _get_src_urls(self, url, page_url=None):\n",
    "        element = self.get_etree_html(url)\n",
    "\n",
    "        if page_url is None:\n",
    "            src_urls, src_names = self.get_page_src_urls(url)\n",
    "        else:\n",
    "            max_page = element.xpath(\"//em[@class='all_pages']\")[0]\n",
    "            max_page = int(max_page.text)\n",
    "\n",
    "            src_urls, src_names = [], []\n",
    "            for id in range(1, max_page + 1):\n",
    "                \n",
    "                page_src_urls, page_names = self.get_page_src_urls(page_url.format(id=id))\n",
    "                if self.args.verbose:\n",
    "                    print(f'page: {id}')\n",
    "                    print(f'page_names: {page_names}')\n",
    "                src_urls += page_src_urls\n",
    "                src_names += page_names\n",
    "        \n",
    "        return src_urls, src_names\n",
    "            \n",
    "    def get_page_src_urls(self, url):\n",
    "        element = Crawler.get_etree_html(url)\n",
    "        page_src_list = element.xpath(\"//h5[contains(@class,'card-title')]/a | //div[@class='wp_entry']//a\")\n",
    "        src_urls = [a.attrib['href'] for a in page_src_list]\n",
    "        src_names = [a.attrib['title'] if a.attrib.has_key('title') else eval(a.attrib['sudyfile-attr'])['title'] for a in page_src_list]\n",
    "        \n",
    "        return src_urls, src_names\n",
    "            \n",
    "    def _get_src_from_page(self, element):\n",
    "        page_src_list = element.xpath(\"//div[@class='wp_articlecontent']//a\")\n",
    "        src_urls = [a.attrib['href'] for a in page_src_list]\n",
    "        src_names = [eval(a.attrib['sudyfile-attr'])['title'] for a in page_src_list]\n",
    "        return src_urls, src_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(debug=False, verbose=True)\n",
      "__main__ - INFO\tDownloading src files for 信息科学技术学院...\n",
      "__main__ - INFO\tDownloading src files for 信息科学技术学院...\n",
      "__main__ - INFO\tDownloading src files for 信息科学技术学院...\n",
      "__main__ - INFO\tDownloading src files for 信息科学技术学院...\n",
      "__main__ - INFO\tgetting the src_urls list of center https://sist.ustc.edu.cn/5111/list.htm...\n",
      "__main__ - INFO\tgetting the src_urls list of center https://sist.ustc.edu.cn/5111/list.htm...\n",
      "__main__ - INFO\tgetting the src_urls list of center https://sist.ustc.edu.cn/5111/list.htm...\n",
      "__main__ - INFO\tgetting the src_urls list of center https://sist.ustc.edu.cn/5111/list.htm...\n",
      "page: 1\n",
      "page_names: ['中国科学技术大学本科生参加暑期交流项目申请表', '缓修成绩取消申请单', '中国科学技术大学录播教室使用申请表', '中国科学技术大学学生“开学考试”成绩登记表', '中国科学技术大学本科生开学考试申请单', '大研（毕设）协议书', '大学生赴院所做大研（毕设）差旅费统计表', '本科生课程请假申请表', '警示期及退学复议学生选课调整申请表']\n",
      "page: 2\n",
      "page_names: ['学生个性化学习申请表（因学习困难申请缓修）', '学生个性化学习申请表（因拟转专业申请缓修）', '试卷送印单', '跨院系调整所修专业申请表', '本科生听课记录表（实验）', '本科生听课记录表（理论）', '本科生学业指导谈话记录（学业警示）', '本科生学业指导谈话记录（通用）', '在读证明——国外']\n",
      "page: 3\n",
      "page_names: ['在读证明——国内']\n",
      "__main__ - INFO\tgetting the src_urls list of center https://sist.ustc.edu.cn/5095/list.htm...\n",
      "__main__ - INFO\tgetting the src_urls list of center https://sist.ustc.edu.cn/5095/list.htm...\n",
      "__main__ - INFO\tgetting the src_urls list of center https://sist.ustc.edu.cn/5095/list.htm...\n",
      "__main__ - INFO\tgetting the src_urls list of center https://sist.ustc.edu.cn/5095/list.htm...\n",
      "page: 1\n",
      "page_names: ['信息科学技术学院学研两会活动项目审批表', '信息科学技术学院团学活动项目审批表', '信息科学技术学院班级活动项目审批表', '信息学院开展学生活动工作流程', '信息学院推荐优秀团员作入党积极分子工作流程', '信息学院就业三方协议领取、换发流程', '信息学院学生活动新闻稿基本格式和要求', '推荐优秀团员作为党的发展对象审核表', '推荐优秀团员作入党积极分子审核表']\n",
      "page: 2\n",
      "page_names: ['中国科学技术大学推荐优秀团员作入党积极分子和党的发展对象工作实施细则', '师生校内常用部门联系方式汇总', '科大人文社科类报告会、研讨会、论坛、讲座审批备案表']\n",
      "__main__ - INFO\tgetting the src_urls list of center https://sist.ustc.edu.cn/5079/list.htm...\n",
      "__main__ - INFO\tgetting the src_urls list of center https://sist.ustc.edu.cn/5079/list.htm...\n",
      "__main__ - INFO\tgetting the src_urls list of center https://sist.ustc.edu.cn/5079/list.htm...\n",
      "__main__ - INFO\tgetting the src_urls list of center https://sist.ustc.edu.cn/5079/list.htm...\n",
      "__main__ - INFO\tAll src pages: \n",
      "[('中国科学技术大学本科生参加暑期交流项目申请表', 'https://sist.ustc.edu.cn/5111/list.htm'), ('缓修成绩取消申请单', 'https://sist.ustc.edu.cn/5095/list.htm'), ('中国科学技术大学录播教室使用申请表', 'https://sist.ustc.edu.cn/5079/list.htm')]\n",
      "__main__ - INFO\tAll src pages: \n",
      "[('中国科学技术大学本科生参加暑期交流项目申请表', 'https://sist.ustc.edu.cn/5111/list.htm'), ('缓修成绩取消申请单', 'https://sist.ustc.edu.cn/5095/list.htm'), ('中国科学技术大学录播教室使用申请表', 'https://sist.ustc.edu.cn/5079/list.htm')]\n",
      "__main__ - INFO\tAll src pages: \n",
      "[('中国科学技术大学本科生参加暑期交流项目申请表', 'https://sist.ustc.edu.cn/5111/list.htm'), ('缓修成绩取消申请单', 'https://sist.ustc.edu.cn/5095/list.htm'), ('中国科学技术大学录播教室使用申请表', 'https://sist.ustc.edu.cn/5079/list.htm')]\n",
      "__main__ - INFO\tAll src pages: \n",
      "[('中国科学技术大学本科生参加暑期交流项目申请表', 'https://sist.ustc.edu.cn/5111/list.htm'), ('缓修成绩取消申请单', 'https://sist.ustc.edu.cn/5095/list.htm'), ('中国科学技术大学录播教室使用申请表', 'https://sist.ustc.edu.cn/5079/list.htm')]\n",
      "__main__ - INFO\tDownloading from src page 0 - Current EXT: htm\n",
      "__main__ - INFO\tDownloading from src page 0 - Current EXT: htm\n",
      "__main__ - INFO\tDownloading from src page 0 - Current EXT: htm\n",
      "__main__ - INFO\tDownloading from src page 0 - Current EXT: htm\n",
      "__main__ - INFO\tFiles of current page: []\n",
      "__main__ - INFO\tFiles of current page: []\n",
      "__main__ - INFO\tFiles of current page: []\n",
      "__main__ - INFO\tFiles of current page: []\n",
      "__main__ - INFO\tDownloading from src page 1 - Current EXT: htm\n",
      "__main__ - INFO\tDownloading from src page 1 - Current EXT: htm\n",
      "__main__ - INFO\tDownloading from src page 1 - Current EXT: htm\n",
      "__main__ - INFO\tDownloading from src page 1 - Current EXT: htm\n",
      "__main__ - INFO\tFiles of current page: []\n",
      "__main__ - INFO\tFiles of current page: []\n",
      "__main__ - INFO\tFiles of current page: []\n",
      "__main__ - INFO\tFiles of current page: []\n",
      "__main__ - INFO\tDownloading from src page 2 - Current EXT: htm\n",
      "__main__ - INFO\tDownloading from src page 2 - Current EXT: htm\n",
      "__main__ - INFO\tDownloading from src page 2 - Current EXT: htm\n",
      "__main__ - INFO\tDownloading from src page 2 - Current EXT: htm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/v-qisichen/interpret/ustc-search-engine/crawl/demo.ipynb Cell 4\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-qisichen/interpret/ustc-search-engine/crawl/demo.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(args)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-qisichen/interpret/ustc-search-engine/crawl/demo.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m sist \u001b[39m=\u001b[39m SISTCrawler(args)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-qisichen/interpret/ustc-search-engine/crawl/demo.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m sist\u001b[39m.\u001b[39;49mcrawl_src(save_path\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m../cache/sist\u001b[39;49m\u001b[39m'\u001b[39;49m, host_url\u001b[39m=\u001b[39;49msist\u001b[39m.\u001b[39;49mmain_url)\n",
      "\u001b[1;32m/home/v-qisichen/interpret/ustc-search-engine/crawl/demo.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-qisichen/interpret/ustc-search-engine/crawl/demo.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=154'>155</a>\u001b[0m src_urls, src_names \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_src_urls(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msrc_store_url, host_url)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-qisichen/interpret/ustc-search-engine/crawl/demo.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=155'>156</a>\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAll src pages: \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(src_names,\u001b[39m \u001b[39msrc_urls))\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-qisichen/interpret/ustc-search-engine/crawl/demo.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=156'>157</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_src_from_store(src_urls, src_names, host_url, save_path)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-qisichen/interpret/ustc-search-engine/crawl/demo.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=158'>159</a>\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDone\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/home/v-qisichen/interpret/ustc-search-engine/crawl/demo.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-qisichen/interpret/ustc-search-engine/crawl/demo.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=100'>101</a>\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDownloading from src page \u001b[39m\u001b[39m{\u001b[39;00mcnt\u001b[39m}\u001b[39;00m\u001b[39m - Current EXT: \u001b[39m\u001b[39m{\u001b[39;00mext\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-qisichen/interpret/ustc-search-engine/crawl/demo.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=101'>102</a>\u001b[0m \u001b[39mif\u001b[39;00m ext \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msrc_ext:     \u001b[39m# url directs to a page but not src file\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-qisichen/interpret/ustc-search-engine/crawl/demo.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=102'>103</a>\u001b[0m     cur_src_urls, cur_src_names \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_src_from_page(url, host_url\u001b[39m=\u001b[39;49mhost_url)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-qisichen/interpret/ustc-search-engine/crawl/demo.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=103'>104</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mverbose:\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-qisichen/interpret/ustc-search-engine/crawl/demo.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=104'>105</a>\u001b[0m         logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFiles of current page: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(cur_src_names,\u001b[39m \u001b[39mcur_src_urls))\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/home/v-qisichen/interpret/ustc-search-engine/crawl/demo.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-qisichen/interpret/ustc-search-engine/crawl/demo.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=138'>139</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_src_from_page\u001b[39m(\u001b[39mself\u001b[39m, url, host_url\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-qisichen/interpret/ustc-search-engine/crawl/demo.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=139'>140</a>\u001b[0m     url \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_urls(url, host_url)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-qisichen/interpret/ustc-search-engine/crawl/demo.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=140'>141</a>\u001b[0m     element \u001b[39m=\u001b[39m Crawler\u001b[39m.\u001b[39;49mget_etree_html(url)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-qisichen/interpret/ustc-search-engine/crawl/demo.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=141'>142</a>\u001b[0m     src_urls, src_names \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_src_from_page(element)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-qisichen/interpret/ustc-search-engine/crawl/demo.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=142'>143</a>\u001b[0m     src_urls \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_urls(src_urls, host_url)\n",
      "\u001b[1;32m/home/v-qisichen/interpret/ustc-search-engine/crawl/demo.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-qisichen/interpret/ustc-search-engine/crawl/demo.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-qisichen/interpret/ustc-search-engine/crawl/demo.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_etree_html\u001b[39m(url):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-qisichen/interpret/ustc-search-engine/crawl/demo.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m0.5\u001b[39m \u001b[39m+\u001b[39m random\u001b[39m.\u001b[39mrandom() \u001b[39m*\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-qisichen/interpret/ustc-search-engine/crawl/demo.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m     response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(url)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-qisichen/interpret/ustc-search-engine/crawl/demo.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m     html \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mcontent\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-qisichen/interpret/ustc-search-engine/crawl/demo.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m etree\u001b[39m.\u001b[39mHTML(html)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/requests/adapters.py:487\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    484\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    486\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 487\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    488\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    489\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    490\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    491\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    492\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    496\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    497\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    498\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    499\u001b[0m     )\n\u001b[1;32m    501\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    502\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/urllib3/connectionpool.py:715\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    712\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    714\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 715\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    716\u001b[0m     conn,\n\u001b[1;32m    717\u001b[0m     method,\n\u001b[1;32m    718\u001b[0m     url,\n\u001b[1;32m    719\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    720\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    721\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    722\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    723\u001b[0m )\n\u001b[1;32m    725\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    729\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/urllib3/connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    462\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    463\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    464\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    465\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    466\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    468\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    469\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/urllib3/connectionpool.py:462\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    461\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 462\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    463\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    464\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    465\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    466\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/anaconda/envs/interpret/lib/python3.9/http/client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1377\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1378\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1379\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/anaconda/envs/interpret/lib/python3.9/http/client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    321\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    322\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/interpret/lib/python3.9/http/client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 281\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    282\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    283\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/anaconda/envs/interpret/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    705\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/interpret/lib/python3.9/ssl.py:1275\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1271\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1272\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1273\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1274\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1275\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1276\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1277\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/anaconda/envs/interpret/lib/python3.9/ssl.py:1133\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1134\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1135\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "args = get_args()\n",
    "print(args)\n",
    "sist = SISTCrawler(args)\n",
    "sist.crawl_src(save_path='../cache/sist', host_url=sist.main_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interpret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
